import os
import re
import base64
import requests
import pandas as pd
import pdfplumber
import docx
from flask import Flask, request, render_template, send_file, jsonify

app = Flask(__name__)
app.config["UPLOAD_FOLDER"] = "uploads"
app.config["OUTPUT_FOLDER"] = "outputs"
os.makedirs(app.config["UPLOAD_FOLDER"], exist_ok=True)
os.makedirs(app.config["OUTPUT_FOLDER"], exist_ok=True)

# ------------------------
# Ù‚Ø±Ø§Ø¡Ø© PDF
# ------------------------
def read_pdf(file_path):
    dfs = []
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                df = pd.DataFrame(table[1:], columns=table[0])
                dfs.append(df)
    return pd.concat(dfs, ignore_index=True) if dfs else None

# ------------------------
# Ù‚Ø±Ø§Ø¡Ø© Word
# ------------------------
def read_docx(file_path):
    doc = docx.Document(file_path)
    dfs = []
    for table in doc.tables:
        data, keys = [], None
        for i, row in enumerate(table.rows):
            text = [cell.text.strip() for cell in row.cells]
            if i == 0:
                keys = text
            else:
                data.append(text)
        if keys:
            dfs.append(pd.DataFrame(data, columns=keys))
    return pd.concat(dfs, ignore_index=True) if dfs else None

# ------------------------
# Ù‚Ø±Ø§Ø¡Ø© ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Qwen
# ------------------------

def read_image_with_qwen(file_path, required_columns=None):
    with open(file_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode("utf-8")

    if len(required_columns) == 1:
        user_prompt = f"what is the {required_columns[0]} in this image?"
    else:
        columns = ",".join(required_columns)
        user_prompt = f"""
          : Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ùˆ ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ùˆ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ ØªØ±Ø§Ù‡Ø§ Ø«Ù… Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¨Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠÙ‡
          {{{columns}}}
          Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø£ÙŠ Ø­Ù‚Ù„ ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠ Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù„Ù‡ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø£Ø±Ø¬Ø¹ Ù‚ÙŠÙ…ØªÙ‡ ÙØ§Ø±ØºØ©"".
        """

  # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Hugging Face API
    HF_API_TOKEN = os.getenv("HF_API_TOKEN")  # ğŸ”¹ Ø­Ø· Ù‡Ù†Ø§ Ø§Ù„Ù€ Access Token Ø¨ØªØ§Ø¹Ùƒ Ù…Ù† https://huggingface.co/settings/tokens
    MODEL_URL = "https://api-inference.huggingface.co/models/ahmed-20033/my-ai-model"
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}

    payload = {
        "inputs": {
            "text": user_prompt,
            "image": f"data:image/jpeg;base64,{image_b64}"
        }
    }

    try:
        response = requests.post(MODEL_URL, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()
        text = result[0].get("generated_text", result[0] if isinstance(result, list) else result)
        if isinstance(text, dict):
            text = text.get("generated_text", "")
        text = str(text).strip()
        print("ğŸ“œ Raw Qwen response:", text)  # Ù„Ù„ØªØµØ­ÙŠØ­
       # 1ï¸âƒ£ Ù‡Ø§Øª ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù„ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ { }
        inside_braces = re.findall(r'\{([^}]*)\}', text, flags=re.MULTILINE)
        if inside_braces:
            # Ù„Ùˆ Ù„Ù‚Ù‰ Ø£Ù‚ÙˆØ§Ø³ØŒ Ø®ÙØ¯ Ø§Ù„Ù„ÙŠ Ø¬ÙˆØ§Ù‡Ø§ Ø¨Ø³
            result = inside_braces
        else:
            # 2ï¸âƒ£ Ù„Ùˆ Ù…ÙÙŠØ´ØŒ Ù‡Ø§Øª Ø§Ù„Ø³Ø·ÙˆØ± Ø§Ù„Ù„ÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ -
            result = re.findall(r'^-.*', text, flags=re.MULTILINE)

        block = "\n".join(result)   # Ø¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯
        matches = re.findall(r'^[^:]*:\s*(.+)$', block, flags=re.MULTILINE)
        # ØªÙ†Ø¸ÙŠÙ:
        values = [
            x.strip(' "\',')    # ÙŠØ´ÙŠÙ„ Ø£Ù‰ Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ " Ø£Ùˆ ' Ø£Ùˆ ,
            for x in matches
            if x.strip(' "\',') != ''
        ]

        print("ğŸ“œ Processed model_text:", values)  # Ù„Ù„ØªØµØ­ÙŠØ­

        if values == []:
            raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©.")

        if required_columns:
            if any("Ù„Ø§ ÙŠÙˆØ¬Ø¯" in v or "Ø®Ø·Ø£" in v or "ØªØ¨Ø­Ø«" in v or "Ù„Ø§ ØªØ­ØªÙˆÙŠ" in v for v in values):
                raise ValueError(
                    f"Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£"
                )
            # Ù†Ø¬Ù…Ø¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± ØªØ§Ù†ÙŠ ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯
            # joined = ",".join(required_columns)
            # Ù†Ø­ÙˆÙ„Ù‡Ø§ Ù„Ù€ list Ø­Ù‚ÙŠÙ‚ÙŠØ©
            required_columns2 = required_columns
            # 1ï¸âƒ£ Ø´ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (ÙÙŠ Ø§Ù„Ù†Øµ ÙƒÙ„Ù‡)
            pattern = r"\b(?:%s)\b" % "|".join(map(re.escape, required_columns2))
            # Ø§Ù…Ø´ÙŠ Ø¹Ù„Ù‰ ÙƒÙ„ Ø¹Ù†ØµØ± (Ø³Ø·Ø±) ÙˆØ¹Ø¯Ù„Ù‘Ù‡
            cleaned_lines = []
            for line in values:
                line_no_names = re.sub(pattern, "", line)
                # Ù†Ø¸Ù‘Ù Ø§Ù„ÙÙˆØ§ØµÙ„ ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª
                cleaned_line = ", ".join(
                    item.strip() for item in line_no_names.split(",") if item.strip()
                )
                cleaned_lines.append(cleaned_line)
            cleaned_lines = [line for line in cleaned_lines if line.strip()]

            if len(cleaned_lines) != len(required_columns2):
                raise ValueError(
                    f"Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ({len(cleaned_lines)}) Ù„Ø§ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ({len(required_columns2)}). Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬: {cleaned_lines}"
                )
            df = pd.DataFrame([cleaned_lines], columns=required_columns) 
            return df
        else:
            return pd.DataFrame([{"Text": text}])

    except Exception as e:
        raise ValueError(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Qwen Ø£Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")

# ------------------------
# Ù‚Ø±Ø§Ø¡Ø© Ø£ÙŠ Ù…Ù„Ù
# ------------------------
def read_file(input_file, required_columns=None):
    if input_file.lower().endswith(".csv"):
        return pd.read_csv(input_file)
    elif input_file.lower().endswith(".xlsx"):
        return pd.read_excel(input_file)
    elif input_file.lower().endswith(".txt"):
        try:
            return pd.read_csv(input_file, delimiter=",")
        except:
            return pd.read_csv(input_file, delimiter="\t")
    elif input_file.lower().endswith(".pdf"):
        return read_pdf(input_file)
    elif input_file.lower().endswith(".docx"):
        return read_docx(input_file)
    elif input_file.lower().endswith(('.png', '.jpg', '.jpeg')):
        return read_image_with_qwen(input_file, required_columns)
    else:
        raise ValueError("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")

# ------------------------
# ØµÙØ­Ø© HTML
# ------------------------
@app.route("/")
def index():
    return render_template("index.html")

# ------------------------
# API Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹
# ------------------------
@app.route("/process", methods=["POST"])
def process():
    file = request.files["file"]
    required_columns = [col.strip() for col in request.form["columns"].split(",") if col.strip()]

    if not file:
        return jsonify({"error": "âŒ Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø±ÙØ¹ Ù…Ù„Ù."}), 400

    file_path = os.path.join(app.config["UPLOAD_FOLDER"], file.filename)
    file.save(file_path)

    try:
        df = read_file(file_path, required_columns)
        if required_columns:
            available_cols = []
            for col in required_columns:
                for df_col in df.columns:
                    if col.strip().lower() == df_col.strip().lower():
                        available_cols.append(df_col)

            # âœ… Ù„Ùˆ Ù…ÙÙŠØ´ Ø£ÙŠ ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙˆØ§Ù„Ù„ÙŠ Ø§ØªÙ‚Ø±Øª
            if not available_cols:
                return jsonify({
                    "error": "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„Ù/Ø§Ù„ØµÙˆØ±Ø©."
                }), 400
        
        # ÙØ­Øµ Ø¥Ø¶Ø§ÙÙŠ: Ø§Ù„ØªØ£ÙƒØ¯ Ø¥Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ù…Ø³ØªØ®Ø±Ø¬Ø©
        if df.empty or df.dropna().empty:
            return jsonify({
                "error": "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø§Ù„ØµÙˆØ±Ø©."
            }), 400

        df = df[available_cols]

        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        df.columns = [re.sub(r'["\[\]]', '', col) for col in df.columns]

        # Ù†Ø®Ø²Ù† Ù†Ø³Ø®Ø© Excel Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ­Ù…ÙŠÙ„
        output_file = os.path.join(app.config["OUTPUT_FOLDER"], file.filename.rsplit(".", 1)[0] + "_filtered.xlsx")
        df.to_excel(output_file, index=False)

        return jsonify({
            "columns": list(df.columns),
            "rows": df.to_dict(orient="records"),
            "download_url": f"/download/{os.path.basename(output_file)}"
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ------------------------
# API Ù„ØªØ­Ù…ÙŠÙ„ Excel
# ------------------------
@app.route("/download/<filename>")
def download(filename):
    file_path = os.path.join(app.config["OUTPUT_FOLDER"], filename)
    if os.path.exists(file_path):
        return send_file(file_path, as_attachment=True)
    return "âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯", 404

@app.route("/health")
def health_check():
    return "OK", 200

# ------------------------
# Run
# ------------------------
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)  
